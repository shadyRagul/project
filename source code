# Step 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# Step 2: Load Dataset
df = pd.read_csv('bengaluru_house_prices.csv')

# Step 3: Basic Exploration
print(df.shape)
print(df.columns)
print(df.head())
print(df.info())
print(df.isnull().sum())
print("Duplicates:", df.duplicated().sum())

# Step 4: Data Cleaning
# Drop unhelpful columns
df = df.drop(['area_type', 'society', 'balcony', 'availability'], axis=1)

# Drop rows with missing values
df = df.dropna()

# Step 5: Feature Engineering
# Convert 'size' to number of bedrooms (BHK)
df['bhk'] = df['size'].apply(lambda x: int(x.split(' ')[0]))

# Clean 'total_sqft' column
def convert_sqft(x):
    try:
        return float(x)
    except:
        tokens = x.split('-')
        if len(tokens) == 2:
            return (float(tokens[0]) + float(tokens[1])) / 2
        return None

df['total_sqft'] = df['total_sqft'].apply(convert_sqft)
df = df.dropna()

# Step 6: Create Price per Square Foot
df['price_per_sqft'] = df['price']*100000 / df['total_sqft']

# Step 7: Dimensionality Reduction (reduce number of locations)
df['location'] = df['location'].apply(lambda x: x.strip())
location_stats = df['location'].value_counts()
locations_less_than_10 = location_stats[location_stats <= 10]
df['location'] = df['location'].apply(lambda x: 'other' if x in locations_less_than_10 else x)

# Step 8: Outlier Removal (optional - based on business understanding)
df = df[df['total_sqft']/df['bhk'] >= 300]

# Step 9: One-Hot Encoding
dummies = pd.get_dummies(df['location'], drop_first=True)
df = pd.concat([df.drop('location', axis=1), dummies], axis=1)

# Step 10: Features and Target
X = df.drop(['price', 'size', 'price_per_sqft'], axis=1)
y = df['price']

# Step 11: Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Step 12: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Step 13: Model Training
model = LinearRegression()
model.fit(X_train, y_train)

# Step 14: Model Evaluation
y_pred = model.predict(X_test)
print("MSE:", mean_squared_error(y_test, y_pred))
print("R¬≤ Score:", r2_score(y_test, y_pred))

# Step 15: Deploy with Gradio
!pip install gradio --quiet

import gradio as gr

# Store columns to match new input later
model_features = X.columns

# Gradio Prediction Function
def predict_price(location, sqft, bath, bhk):
    # Encode location
    loc_data = np.zeros(len(model_features))
    if location in model_features:
        loc_index = list(model_features).index(location)
        loc_data[loc_index] = 1

    # Fill other inputs
    loc_data[list(model_features).index('total_sqft')] = sqft
    loc_data[list(model_features).index('bath')] = bath
    loc_data[list(model_features).index('bhk')] = bhk

    # Scale and predict
    loc_data_scaled = scaler.transform([loc_data])
    pred = model.predict(loc_data_scaled)[0]
    return round(pred, 2)


    # Create input UI
# locations = sorted(df['location'].unique()) # This line is causing the error.
locations = [loc for loc in model_features if loc not in ['total_sqft', 'bath', 'bhk']] # locations should be picked up from model_features
# locations should contain the dummy variable location names, which were generated during one-hot encoding.

gr.Interface(
    fn=predict_price,
    inputs=[
        gr.Dropdown(locations, label="Location"),
        gr.Number(label="Total Square Feet"),
        gr.Number(label="Number of Bathrooms"),
        gr.Number(label="Number of Bedrooms (BHK)")
    ],
    outputs=gr.Number(label="Predicted Price (Lakh ‚Çπ)"),
    title="üè° Bengaluru House Price Predictor",
    description="Enter the property details to get an estimated selling price."
).launch()
